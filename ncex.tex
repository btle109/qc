\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{tcolorbox}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{hyperref}
\usepackage{braket}
\title{Exercises from Nielsen and Chuang}
\author{}
\date{}

\begin{document}
\maketitle
\tableofcontents
\newpage
\section{2.1.5 Eigenvectors and eigenvalues}
(2.11) Find eigenvectors, eigenvalues, and diagonal representations of Pauli X,Y,Z.
\begin{tcolorbox}\textbf{Solution:}
	The eigenvalues of all Pauli matrices are $1,-1$.
	The eigenvectors are as follows:
	$$ \ket{\psi}_{x+} = \frac{1}{\sqrt2}(\ket0 + \ket1), \ket{\psi}_{x-}=\frac{1}{\sqrt2}(\ket0 - \ket1)$$
	$$\ket{\psi}_{y+} = \frac{1}{\sqrt2}(\ket0 + i\ket1), \ket{\psi}_{y-} = \frac{1}{\sqrt2}(\ket0 -i\ket1)$$
	$$\ket{\psi}_{z+} = \ket0, \ket{\psi}_{z-} = \ket{1}$$
	A diagonal representation is defined as $A = \sum_i \lambda_i \bra{i}\ket{i}$ where the vectors $i$ form an orthonormal set of eigenvectors. Thus, the diagonal representations of any Pauli matrix is:
	$$\sigma = \ket{\psi}_{+}\bra{\psi}_{+} - \ket{\psi}_{-}\bra{\psi}_{-}$$
\end{tcolorbox}
(2.12) Prove the matrix $\begin{bmatrix} 1 & 0 \\ 1 & 1 \end{bmatrix}$ is not diagonalizable.
\begin{tcolorbox}\textbf{Solution:}
	The eigenvalues of the matrix are $1$ with algebraic multiplicity $2$ (easily seen since it is a lower triangular matrix). Then, the eigenvectors are $\begin{bmatrix} 0 \\ \alpha \end{bmatrix}$, for $\alpha \in \mathbb{C}$.

A matrix is diagonalizable iff there exists a basis of eigenvectors of the matrix. There cannot be a matrix of eigenvectors since there is only one linearly independent eigenvector of the matrix, which is less than the dimension of the matrix. Thus it cannot form a basis and it cannot be diagonalizable.
\end{tcolorbox}
\section{2.1.6 Adjoints and Hermitian Operators}
(2.13) If $\ket{w}$ and $\ket{v}$ are any two vectors, show that $(\ket{w}\bra{w})^\dag = \ket{v}\bra{w}$.
\begin{tcolorbox}\textbf{Solution:}
	$(\ket{w}\bra{v})^\dag = \bra{v}^\dag\ket{w}^\dag = \ket{v}\bra{w}.$
\end{tcolorbox}
(2.14) (Anti-linearity of the adjoint) Show that the adjoint operation is antilinear,
$$(\sum_i a_iA_i)^\dag = \sum_i a_i^* A_i^\dag$$
\begin{tcolorbox}\textbf{Solution:}
	$$(\sum_i a_i A_i)^\dag = \sum_i a_i^\dag A_i^\dag = \sum_i a_i^* A_i^\dag$$
	where $a^\dag = (a^*)^T = a^*$ since $a$ is a scalar.
\end{tcolorbox}
(2.15) Show that $(A^\dag)^\dag = A$
\begin{tcolorbox}\textbf{Solution:}
	$$(\ket{v}, A\ket{w}) = (A^\dag \ket{v}, \ket{w}) = (\ket{v}, (A^\dag)^\dag \ket{w})$$
	$$\iff A = (A^\dag)^\dag$$
\end{tcolorbox}
(2.16) Show any projector P satisfies $P^2 = P$
\begin{tcolorbox}\textbf{Solution:}
	A projector is defined as $P = \sum_i \ket{i}\bra{i}$
	$$\implies P^2 = \sum_{ij} \ket{i}\bra{i} \ket{j}\bra{j} = \sum_{ij} \ket{i} \delta_{ij} \bra{j} = \sum_i \ket{i}\bra{i} = P.$$
\end{tcolorbox}
(2.17) Show that a normal matrix is Hermitian iff it has real eigenvalues.
\begin{tcolorbox}\textbf{Solution:}
	\begin{proof} First we prove that a normal matrix is Hermitian if it has real eigenvalues.\\
	Suppose we have matrix $A$ such that $A=A^\dag$ and $AA^\dag = A^\dag A$. \\
	Then, suppose $A$ has eigenvalue $\lambda \iff Av = \lambda v$ for some nonzero $v$.
	Then, we see that $v^\dag A^\dag = v^\dag A =\lambda^\dag v$, where the first equality is given by the fact the matrix is Hermitian.\\
	Consider $$Av = \lambda v$$
	$$\iff v^\dag A v = v^\dag \lambda v$$
	$$\iff \lambda^\dag v^\dag v = \lambda v^\dag v \iff \lambda^\dag =  \lambda$$
	$\iff \lambda$ is real.
	Then we prove if a normal matrix has real eigenvalues then it is Hermitian.
	Suppose all eigenvalues are real, then $\lambda = \lambda^\dag$. We see that $Av = \lambda v \iff v^\dag A^\dag = \lambda v^\dag$.
	Then, left multiplying the first equation by $v^\dag$ and right multiplying the second equation by $v$ yields:
	$$v^\dag A v = \lambda |v|^2 = v^\dag A^\dag v \iff A = A^\dag$$
\end{proof}

\end{tcolorbox}
	(2.18) Show that all eigenvalues of a unitary matrix have modulus 1, that is, can be written in the form $e^{i\theta}$ for some real $\theta$.
	\begin{tcolorbox}\textbf{Solution:}
	$$Uv = \lambda v \iff v^\dag U^\dag Uv = v^\dag |\lambda|^2 v \iff v^\dag v = v^\dag |\lambda|^2 v$$
	$$\iff |\lambda|^2 = 1$$
	\end{tcolorbox}
(2.19) Show Pauli matrices are Hermitian and unitary.
\begin{tcolorbox}\textbf{Solution:}
	Trivial to see Pauli matrices are equal to adjoints and to use matrix multiplication to check unitary.
\end{tcolorbox}
(2.20) Suppose $A'$ and $A''$ are matrix representations of an operator $A$ on a vector space $V$ with respect to two different orthonormal bases, $\ket{v_i}$ and $\ket{w_i}$. Then the elements of $A'$ and $A''$ are $A'_{ij} = \braket{v_i|A|v_j}$ and $A''_{ij} = \braket{w_i | A|w_j}$. Characterize the relationship between $A'$ and $A''$.
\begin{tcolorbox}\textbf{Solution:}
	We use the change of basis theorem.
	Define $P = \sum_i \ket{w_i}\bra{v_i} \implies P^\dag = \sum_i \ket{v_i}\bra{w_i}$.
Then, the elements of $P^\dag A' P =  \sum_{ijklmn}\braket{v_i  \ket{v_m}\bra{w_n}|A|\ket{w_k}\bra{v_l} v_j} = \sum_{ij} \braket{w_i|A|w_j} = A''.$
\end{tcolorbox}
(2.23) Show that the eigenvalues of a projector $P$ are all either 0 or 1.
\begin{tcolorbox}
	Suppose we have projector $P = \sum_i \ket{i} \bra{i}$. For any nonzero vector $\ket{v}$, then $P\ket{v} = \delta_{iv}\ket{v} \iff $ all eigenvectors for $P$ are either 0 or 1.
\end{tcolorbox}
(2.24) (Hermiticity of positive operators) Show that a positive operator is Hermitian.
\begin{tcolorbox}\textbf{Solution:}
	Define $B$, $C$ as follows: $$ B = \frac12 (A+A^\dag), C = \frac12 i(A-A^\dag)$$
	We can see that $B + iC = \frac12 (A+A^\dag) - \frac12 (A - A^\dag)=  A$ as is necessary.
	Then, $\braket{\psi|A|\psi} > 0$ for all $\ket{\psi} \iff \braket{\psi|B|\psi} + i \braket{\psi|C|\psi}$.
	$$\iff \braket{\psi|C|\psi} = 0$$ due to the complex scalar. Therefore it must be that $A=B$, which is Hermitian.
\end{tcolorbox}
(2.25) Show that for any operator $A, A^\dag A$ is positive.
\begin{tcolorbox}\textbf{Solution:}
	Suppose $A\ket{v} = \ket{w}$. Then, $\bra{v} A^\dag A\ket{v} = \braket{w|w} = |w|^2 > 0$.
\end{tcolorbox}

\section{2.1.7 Tensor Products}
(2.26) Let $\ket{\psi} = \frac{\ket0 + \ket1}{\sqrt{2}}$. Write out $\ket{\psi}^{\otimes2}, \ket{\psi}^{\otimes3}$ explicity, both in terms of tensor products and using the Kronecker product.
\begin{tcolorbox}\textbf{Solution:}
$\ket{\psi}^{\otimes2} = \frac12 (\ket{00} + \ket{01} + \ket{10} + \ket{11}) = \frac12 \begin{bmatrix} \psi \\ \psi \end{bmatrix} = \frac12 \begin{bmatrix} 1 \\ 1 \\ 1 \\ 1 \end{bmatrix}$
$$\ket{\psi}^{\otimes3} = \frac{\sqrt2}{4} (\ket{000} + \ket{010} + \ket{100} + \ket{110} + \ket{001} + \ket{011} + \ket{101} + \ket{111})$$
$$= \frac{\sqrt{2}}{4} \begin{bmatrix} \psi \\ \psi \\ \psi \\ \psi \end{bmatrix} = \begin{bmatrix} 1_1 \\ \vdots \\ 1_8\end{bmatrix}$$
\end{tcolorbox}
(2.27) Calculate the matrix representation of the tensor products of Pauli operators $X_1 Z_2, I_1 X_2, X_1 I_2$
. Is the tensor product commutative?
\begin{tcolorbox}\textbf{Solution:}
	$$X_1 Z_2 = \begin{bmatrix} 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & -1 \\ 1 &0 & 0 & 0 \\ 0 & -1 & 0 & 0 \end{bmatrix}, I_1X_2 = \begin{bmatrix}  0 & 1 & 0 & 0 \\  1 & 0 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0\end{bmatrix}, X_1I_2 = \begin{bmatrix} 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \\ 1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \end{bmatrix}$$
	The tensor product is not commutative.
\end{tcolorbox}
(2.28) Show the tranpose, complex conjugation, and adjoint operators distribute over tensor product.
\begin{tcolorbox}\textbf{Solution:}
	The elements of $(A\otimes B)^*$ are $(A_{ij}B)^* = A_{ij}^* B_{mn}^*$, since $(zw)* =z*w*$. This can be more rigorously expanded. The same follows for transpose and since adjoint is both conjugation and transpose, it commutes too.
\end{tcolorbox}
(2.29) Show the tensor product of two unitary operators is unitary.
\begin{tcolorbox}\textbf{Solution:}
	Suppose we have $U \otimes V$, where $U$ and $V$ are unitary $\iff UU^\dag = I, VV^\dag = I$. Since the adjoint distributes over tensor product, $(U \otimes V)^\dag = U^\dag \otimes V^\dag \iff (U\otimes V)(U^\dag \otimes V^\dag) = (UU^\dag \otimes VV^\dag)= I^{mn}$ where $m$ is dim $U$ and $n$ is dim $V$.
\end{tcolorbox}
(2.30) Show that the tensor product of two Hermitian operators is Hermitian.
\begin{tcolorbox}\textbf{Solution:}
	Suppose we have $A \otimes B$ where $A,B$ are Hermitian. Since adjoint distributes over tensor product,
	$$(A\otimes B)^\dag = A^\dag \otimes B^\dag = A \otimes B$$
\end{tcolorbox}
(2.31) Show the tensor product of two positive operators is positive.
\begin{tcolorbox}\textbf{Solution:}
	Suppose we have positive operators $A,B$. Then $\braket{\psi |A \otimes B|\psi>} = \braket{\psi|A|\psi} \otimes \braket{\psi|B|\psi}$, where each side of the tensor product is greater than zero which then implies the tensor product is positive.
\end{tcolorbox}
(2.32) Show the tensor product of two projectors is a projector.
\begin{tcolorbox}\textbf{Solution:}
	Consider $P_1 = \sum_i \ket{i} \bra{i}, P_2 = \sum_j \ket{j} \bra{j}$. Then, $P_1 \otimes P_2$ is Hermitian (see exercise 2.30). Then, see $(P_1 \otimes P_2)^2 = P_1P_1 \otimes P_2P_2 = P_1 \otimes P_2$. Thus the tensor product of two projectors is a projector.
\end{tcolorbox}
(2.33) The Hadamard operator on one qubit may be written:
$$H = \frac{1}{\sqrt2} [(\ket{0} + \ket{1})\bra{0} + (\ket0 - \ket1)\bra1]$$
Show that the Hadamard transform on $n$ qubits, $H^{\otimes n}$ may be written as:
$$H^{\otimes n} =  \frac{1}{\sqrt{2^n}} \sum_{x,y} (-1)^{xy} \ket{x}\bra{y}$$
Write out an explicit matrix representation for $H^{\otimes2}.$
\begin{tcolorbox}\textbf{Solution:}
	$$H^{\otimes2} = \frac12 \begin{bmatrix} 1 & 1 & 1 & 1 \\ 1 & -1 & 1 & -1 \\ 1 & 1 & -1 & -1 \\ 1 & -1 & -1 & 1 \end{bmatrix}$$
	We prove by induction.
	\begin{proof}
		We see that $H^{\otimes1} = \frac{1}{\sqrt{2}}\sum_{x,y} (-1)^{xy} \ket{x}\bra{y}  = \frac{1}{\sqrt2} \ket{0}\bra{0} + \ket{1}\bra{0} + \ket{0}\bra{1} - \ket{1}\bra{1}= H$. Then, assume it is true for $H^{\otimes n-1}.$ We prove it is true for $H^{\otimes n}$.
		\begin{align*}
			H^{\otimes n} &= \frac{1}{\sqrt{2^{n-1}}} \sum+{x,y} (-1)^{xy} \ket{x}\bra{y} \otimes H\\
				      &= \frac{1}{\sqrt{2^n}} \sum+{x,y} (-1)^{xy} \ket{x}\bra{y}  
		\end{align*}
	\end{proof}
\end{tcolorbox}
\section{2.2.2 Evolution}
(2.51) Verify that the Hadamard gate $H$ is unitary.
\begin{tcolorbox}\textbf{Solution:}
	$$HH^T = H^TH = H^2 = \frac12 \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} \begin{bmatrix} 1 & 1 \\ 1 & -1 \end{bmatrix} = \frac12 \begin{bmatrix}2 & 0 \\ 0 & 2 \end{bmatrix} = I.$$
\end{tcolorbox}
(2.52) Verify that $H^2 = I$.
\begin{tcolorbox}\textbf{Solution:}
	See above.
\end{tcolorbox}
(2.55) Define $U(t_1,t_2) \equiv exp[\frac{-i H(t_2 - t_1)}{\hbar}]$. Show $U(t_1, t_2)$ is unitary.
\begin{tcolorbox}\textbf{Solution:}
	\begin{align*}
		U^\dag(t_1, t_2) &= exp [\frac{-i^\dag}{\hbar} H^\dag(t_2-t_1)] = exp [\frac{i}{\hbar} H(t_2-t-1)]\\
		UU^\dag &=  exp [ \frac{i-i}{\hbar}H(t_2 - t_1)] = exp[0] = I
\end{align*}
	where the last equality is from exponential operator on zero matrix.
\end{tcolorbox}
(2.56) Use spectral decomposition to show that $K \equiv ilog(U)$ is Hermitian for any unitary $U$, and thus $U = exp(iK)$ for some Hermitian $K$.
\begin{tcolorbox}\textbf{Solution:}
	Any eigenvalue of a unitary matrix has length $1$. Since the eigenvalues are in a Hilbert space and therefore complex numbers, any eigenvalue of any unitary matrix can be represented as $\lambda_i = e^{i\theta_i}$. Then, performing the spectral decomposition of arbitrary unitary matrix $U$:
	$$U = -i \sum_j \log(e^{i\theta_j} \ket{j}\bra{j}) = -i \sum_j i\theta_j \ket{j}\bra{j} = \sum_j \theta_j\ket{j}\bra{j}$$
	$$\implies U^\dag = U$$. Therefore $K$ as defined is Hermitian for any unitary $U$. To show that $U = exp(iK),$ multiply both sies by $i$ and apply the exponentiation operator to both sides.
\end{tcolorbox}

\section{2.3 Superdense Coding}
(2.69) Verify the Bell basis forms an orthonormal basis for the two qubit state space.
\begin{tcolorbox}{Solution:}
	Trivial, convert to matrix form and perform pairwise dot product and verify norm is 1.
\end{tcolorbox}
\section{2.4.2 Density Operator Properties}
\section{2.4.3 Reduced Density Operator}
\dots Skipping for now, even though these are fun.

\end{document}
